import argparse
import requests
import csv
import os
import sys
import re

API_KEY = os.environ.get("GOOGLE_API_KEY", "").strip()
CX      = os.environ.get("GOOGLE_CX_ID", "").strip()
if not API_KEY or not CX:
    raise SystemExit("[ERROR] GOOGLE_API_KEY / GOOGLE_CX_ID í™˜ê²½ë³€ìˆ˜ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")

LOG_FILE = "search_log.csv"

# ===== ì½˜ì†” ì•ˆì „ ì¶œë ¥ ì„¤ì • (ìœˆë„ìš° cp949 ëŒ€ë¹„) =====
def _configure_stdout():
    try:
        enc = getattr(sys.stdout, "encoding", None) or "utf-8"
        # í˜„ìž¬ ì½˜ì†” ì¸ì½”ë”©ì„ ìœ ì§€í•˜ë˜, ì¸ì½”ë”© ë¶ˆê°€ ë¬¸ìžë¥¼ ì¹˜í™˜í•´ì„œ ì ˆëŒ€ í¬ëž˜ì‹œ ì•ˆ ë‚˜ê²Œ
        sys.stdout.reconfigure(encoding=enc, errors="replace")
        sys.stderr.reconfigure(encoding=enc, errors="replace")
    except Exception:
        pass

def safe(s: str) -> str:
    """í˜„ìž¬ stdout ì¸ì½”ë”©ìœ¼ë¡œ ì•ˆì „í•˜ê²Œ ë³€í™˜"""
    enc = (getattr(sys.stdout, "encoding", None) or "utf-8")
    return (str(s) if s is not None else "").encode(enc, errors="replace").decode(enc, errors="replace")

_configure_stdout()

# ===== ìž‘í’ˆëª… ì •ê·œí™” =====
def normalize(s: str) -> str:
    return re.sub(r"\s+", "", s or "").strip()

# ===== Google ê²€ìƒ‰ =====
def google_search_api(query: str, work_title: str, n: int = 10):
    url = "https://www.googleapis.com/customsearch/v1"
    params = {"key": API_KEY, "cx": CX, "q": query, "num": n}
    r = requests.get(url, params=params, timeout=10)
    r.raise_for_status()
    data = r.json()
    results = []

    must_keywords = ["ì´¬ì˜ì§€", "ì´¬ì˜ ìž¥ì†Œ", "ì´¬ì˜ìž¥ì†Œ"]

    norm_title = normalize(work_title)

    for i, item in enumerate(data.get("items", []), 1):
        link = item.get("link")
        title = item.get("title") or ""
        if not link or "instagram.com" in link:
            continue

        # ðŸ”¹ í•„í„° ì¡°ê±´: ì›ëž˜ ì œëª© or ê³µë°± ì œê±°í•œ ì œëª© í¬í•¨
        if work_title not in title and norm_title not in normalize(title):
            continue
        if not any(kw in title for kw in must_keywords):
            continue

        results.append({
            "rank": len(results) + 1,
            "title": title,
            "url": link,
            "snippet": item.get("snippet")
        })

        if len(results) >= n:
            break
    return results

# ===== ë¡œê·¸ ì €ìž¥ =====
def save_log(work_title, results):
    with open(LOG_FILE, "w", newline='', encoding="utf-8") as f:
        writer = csv.DictWriter(f, fieldnames=["work_title", "title", "url"])
        writer.writeheader()
        for r in results:
            writer.writerow({
                "work_title": work_title,
                "title": r["title"],
                "url": r["url"]
            })

# ===== ì‹¤í–‰ ì—”íŠ¸ë¦¬ =====
def main():
    if len(sys.argv) < 2:
        print("Usage: python google.py <ìž‘í’ˆëª…>")
        sys.exit(1)

    work_title = " ".join(sys.argv[1:]).strip()  # ðŸ”¹ ì—¬ëŸ¬ ë‹¨ì–´ ìž…ë ¥ í—ˆìš©
    query = f"{work_title} í•œêµ­ ì´¬ì˜ì§€"

    print(f"1ë‹¨ê³„: ì—…ë°ì´íŠ¸ ì‹œìž‘: {safe(query)}")
    results = google_search_api(query, work_title, n=10)
    save_log(work_title, results)

    print(f"[INFO] search_log.csv ì €ìž¥ ì™„ë£Œ ({len(results)}ê±´)")
    for r in results:
        # ìœ ë‹ˆì½”ë“œ í™”ì‚´í‘œ ëŒ€ì‹  ASCII ì‚¬ìš© + safe()ë¡œ ì½˜ì†” ì¸ì½”ë”© ë°©ì–´
        print(f"[{r['rank']}] {safe(r['title'])} -> {r['url']}")

if __name__ == "__main__":
    main()
